---
title: "BDC"
author: "Vasileios Stavropoulos"
date: "`r Sys.Date()`"
output: html_document
---
Prepare Library
```{r}
message=FALSE
echo=FALSE
warnings=FALSE
error=FALSE
suppressWarnings({
  
  suppressMessages({
  
library(tidyverse)
library(tidymodels)
library(purrr)
library(haven)
library(scales)
library(ggpubr)
library(patchwork)
library(psych)
library(rstatix)
library(rcompanion)
library(broom)
library(knitr)
library(readr)
library(here)
library(psych)
library(officer)
library(ggplot2)
library(dplyr)
library(broom.mixed) 
library(dotwhisker)  
library(rstanarm)
library(agua)
library(parsnip)
library(plyr)
library(themis)
library(DMwR)
library(naivebayes)
library(yardstick)
library(vip)
library(palmerpenguins)
library(nnet)
library(Metrics)
library(kernlab)
library(e1071)
library(usethis)
library(devtools)
library(discrim)
library(ranger) 
library(git4r)
library(ggfortify)
library(caret)
library(doParallel) 
library(dials) 
    
  
})
})
```

Import and prepare the data for the analyses
```{r}
message=FALSE
echo=FALSE
warnings=FALSE
error=FALSE
suppressWarnings({
  
  options(scipen = 9999, digits=3, max.print=999999, show.signif.stars=TRUE)
  
  data<-read_sav("C:/Users/vasil/Desktop/BDC/BDC.sav")
  
  data1<-data[c("Q6","Q37", "Q38", "Q39", "Q40", "Q42", "Q43", "Q44", "Q45", "Q46", "Q47", "Q48", "Q49", "Q50", "Q112", "Q113", "Q114", "Q115", "Q116", "Q117", "Q118", "Q119", "Q120", "Q121", "Q122", "Q123", "Q126", "Q127", "Q128", "Q129", "Q130", "Q131")]
DataNN<-data1%>%setNames(c("AGE", "GDT1", "GDT2", "GDT3", "GDT4", "IGD1", "IGD2", "IGD3", "IGD4", "IGD5", "IGD6", "IGD7", "IGD8", "IGD9", "ID1", "ID2", "ID3", "ID4", "IM1", "IM2", "IM3", "IM4", "IM5", "COMP1", "COMP2", "COMP3", "PE1", "PE2", "PE3", "PE4", "PE5", "PE6"))
DataN<-DataNN%>%mutate(GDT1=case_when(GDT1>2~1,
                                      GDT1<3~0,
                                      TRUE~NA_real_),
                       GDT2=case_when(GDT2>2~1,
                                      GDT2<3~0,
                                      TRUE~NA_real_),
                       GDT3=case_when(GDT3>2~1,
                                      GDT3<3~0,
                                      TRUE~NA_real_),
                       GDT4=case_when(GDT4>2~1,
                                      GDT4<3~0,
                                      TRUE~NA_real_),
                       IGD1=case_when(IGD1>2~1,
                                      IGD1<3~0,
                                      TRUE~NA_real_),
                       IGD2=case_when(IGD2>2~1,
                                      IGD2<3~0,
                                      TRUE~NA_real_),
                       IGD3=case_when(IGD3>2~1,
                                      IGD3<3~0,
                                      TRUE~NA_real_),
                       IGD4=case_when(IGD4>2~1,
                                      IGD4<3~0,
                                      TRUE~NA_real_),
                       IGD5=case_when(IGD5>2~1,
                                      IGD5<3~0,
                                      TRUE~NA_real_),
                       IGD6=case_when(IGD6>2~1,
                                      IGD6<3~0,
                                      TRUE~NA_real_),
                       IGD7=case_when(IGD7>2~1,
                                      IGD7<3~0,
                                      TRUE~NA_real_),
                       IGD8=case_when(IGD8>2~1,
                                      IGD8<3~0,
                                      TRUE~NA_real_),
                       IGD9=case_when(IGD9>2~1,
                                      IGD9<3~0,
                                      TRUE~NA_real_))
DataM<-DataN%>%mutate(GDTTotal=GDT1+GDT2+GDT3+GDT4)%>%mutate(IGDTTotal=IGD1+IGD2+IGD3+IGD4+IGD5+IGD6+IGD7+IGD8+IGD9)%>%mutate(IDTotal=ID1+ID2+ID3+ID4)%>%mutate(IMTotal=IM1+IM2+IM3+IM4+IM5)%>%mutate(COMPTotal=COMP1+COMP2+COMP3)%>%mutate(PETotal=PE1+PE2+PE3+PE4+PE5+PE6)
DATAAIGD<-DataM[c("GDTTotal", "IDTotal", "IMTotal", "COMPTotal")]
DATAAIIGD<-DataM[c("IGDTTotal", "IDTotal", "IMTotal", "COMPTotal")]
GDTD<-na.omit(DATAAIGD)
IGDD<-na.omit(DATAAIIGD)
GDTD<-GDTD%>%mutate(GDTTotal=case_when(GDTTotal==4~1,
                                       GDTTotal==3~1,
                                      GDTTotal<3~0,
                                      TRUE~NA_real_))
GDTD<-GDTD %>% 
  mutate(GDTTotal = case_when(GDTTotal == 1 ~ "Yes",
                             GDTTotal == 0 ~ "No"))
IGDD<-IGDD%>%mutate(IGDTTotal=case_when(IGDTTotal==9~1,
                                       IGDTTotal==8~1,
                                       IGDTTotal==7~1,
                                       IGDTTotal==6~1,
                                       IGDTTotal==5~1,
                                      IGDTTotal<5~0,
                                      TRUE~NA_real_))
IGDD<-IGDD %>% 
  mutate(IGDTTotal = case_when(IGDTTotal == 1 ~ "Yes",
                             IGDTTotal == 0 ~ "No"))
  GDTDiag<-GDTD%>%setNames(c("GDDiag", "IDTotal", "IMTotal", "COMPTotal")) 
  IGDDiag<-IGDD%>%setNames(c("IGDDiag", "IDTotal", "IMTotal", "COMPTotal"))
  WHOT<-table(GDTDiag$GDDiag)
  APAT<-table(IGDDiag$IGDDiag)
}) 
```
 
 Compare WHO and APA Classifications 
 
```{r}
  ComparisonWHOandAPA<-rbind(WHOT, APAT)
  kable(ComparisonWHOandAPA)
  
  ChiSqu<-chisq.test(ComparisonWHOandAPA)
  Cram<-cramer_v(ComparisonWHOandAPA)
  
  ChiSqu
  Cram

```
Prepare the training and testing data for the classification supervised algorithms based on the WHO criteria

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
suppressWarnings({
  
  suppressMessages({
GDTDiag$GDDiag=as_factor(GDTDiag$GDDiag)
prior_dist <- rstanarm::student_t(df = 7, location = 0, scale = 2.5)
set.seed(123)
data_split <- initial_split(GDTDiag, prop = 3/4, strata = GDDiag, breaks = 4, pool = 0.1)
# Create data frames for the two sets:
train_data_GD <- training(data_split)
test_data_GD  <- testing(data_split)
#Crossvalidation split
set.seed(123)
folds <- vfold_cv(train_data_GD, v = 10)
TRGDTab<-table(train_data_GD$GDDiag)
TESTGDTab<-table(test_data_GD$GDDiag)
})
})
summary(train_data_GD)
```


Compare the composition of training and testing data

```{r}
ComparisonTrainingandTesting<-rbind(TRGDTab, TESTGDTab)
  kable(ComparisonTrainingandTesting)
  
  TTChiSqu<-chisq.test(ComparisonTrainingandTesting)
  TTCram<-cramer_v(ComparisonTrainingandTesting)
  
  TTChiSqu
  TTCram
```

Introduce, prepare and bake the prediction recipe
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 9999, digits=3, max.print=9999999, show.signif.stars=TRUE)
set.seed(123)
GD_rec <- 
  recipe(GDDiag~ ., data = train_data_GD)%>% step_smote(GDDiag, over_ratio = 0.25)%>%step_zv(all_predictors())%>%step_nzv(all_predictors())%>%step_corr(all_predictors())%>%  step_normalize(all_numeric_predictors())%>%prep()

train_data_GD_b<-bake(GD_rec, new_data = train_data_GD)
test_data_GD_b<-bake(GD_rec, new_data = test_data_GD)
 describe(train_data_GD_b)
 describe(test_data_GD)

```
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 9999, digits=3, max.print=9999999, show.signif.stars=TRUE)
set.seed(123)
train_boot <- bootstraps(train_data_GD, strata = GDDiag)
```

Introduce the models to later mix with the baked recipe to create the workflows. A model is composed by a type, a mode and an engine.
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 9999, digits=3, max.print=9999999, show.signif.stars=TRUE)
set.seed(123)
## token model
twt_null <- null_model()%>%
  set_engine("parsnip")%>%
  set_mode("classification")
## model specification LASSO
lasso_spec <- multinom_reg(penalty = 0.1, mixture = 1)%>%
  set_mode("classification")%>%
  set_engine("glmnet")
# model specification Naive Bayes
nb_spec <- naive_Bayes()%>%
  set_mode("classification")%>%
  set_engine("naivebayes")
# model spec random forest
ranger_spec<-rand_forest()%>% 
  set_engine("ranger", importance = "impurity")%>% 
  set_mode("classification")
##model spec log_regression
logreg_spec <- logistic_reg()%>% 
  set_engine("glm")%>% 
  set_mode("classification")
##model spec Kernel
svm_spec <- svm_rbf(mode = "classification", 
                    engine = "kernlab",
            cost = 1, rbf_sigma = 0.01)
```
Mixing Recipe and Models to Create Workflows
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
set.seed(123)
#Null
Null_workflow <- workflow() %>% 
  add_recipe(GD_rec) %>% 
  add_model(twt_null)
#Lasso 
lasso_workflow <- workflow()%>% 
  add_recipe(GD_rec)%>% 
  add_model(lasso_spec)
#Naive Bayes 
NB_workflow <- workflow()%>% 
  add_recipe(GD_rec) %>% 
  add_model(nb_spec)
#Random Forests 
RF_workflow <- workflow()%>% 
  add_recipe(GD_rec) %>% 
  add_model(ranger_spec)
#Log_GLM_Workflow
LOGGLM_workflow <- workflow()%>% 
  add_recipe(GD_rec) %>% 
  add_model(logreg_spec)
#Kernel
Kernel_workflow<-workflow()%>% 
  add_recipe(GD_rec)%>% 
  add_model(svm_spec)
```

Fitting/training the workflows using the training data
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 9999, digits=3, max.print=9999999, show.signif.stars=TRUE)
Null_fit<-Null_workflow%>%fit(train_data_GD_b)
Null_fit  
Lasso_fit<-lasso_workflow%>%fit(train_data_GD_b)
Lasso_fit
RF_fit<-RF_workflow%>%fit(train_data_GD_b)
RF_fit
LogReg_fit<-LOGGLM_workflow%>%fit(train_data_GD_b)
LogReg_fit
Kernel_fit<-Kernel_workflow%>%fit(train_data_GD_b)
Kernel_fit
NB_fit<-NB_workflow%>%fit(train_data_GD_b)
NB_fit
```
Predict Results on the Testing Data prior Tuning for Lasso, Naive Bayes, Random Forests.
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Null_Model_Untuned
results_NF <- test_data_GD_b%>%select(GDDiag)%>% 
  bind_cols(Null_fit%>% 
              predict(new_data = test_data_GD_b))%>% 
  bind_cols(Null_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_NF)
describe(results_NF)

```
Random Forests Untuned
```{r}
#RF_Untuned
results_RF <- test_data_GD_b %>% select(GDDiag)%>% 
  bind_cols(RF_fit %>% 
              predict(new_data = test_data_GD_b))%>% 
  bind_cols(RF_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_RF)
describe(results_RF)
```
```{r}
#LoReg_Untuned
results_LR <- test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols (LogReg_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols( LogReg_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_LR)
describe(results_LR)
```

```{r}
#Kernel_SVM_Untuned
results_Kern<-test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols (Kernel_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols(Kernel_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_Kern)
describe(results_Kern)
```

```{r}
#Lasso_Untuned
results_Lasso<-test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols( Lasso_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols( Lasso_fit%>% 
             predict(new_data = test_data_GD_b, type = "prob"))
kable(results_Lasso)
describe(results_Lasso)
```

```{r}
#NB_Fit_Untuned
results_NB <- test_data_GD_b %>% select(GDDiag) %>% 
 bind_cols(NB_fit %>% 
             predict(new_data = test_data_GD_b)) %>% 
  bind_cols( NB_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_NB)
describe(results_NB)
```

Get the prediction fit for all the untuned algorithms
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Collect precision metrics concurrently
ev_met1<-metric_set(ppv, f_meas)

#NF_Workflow
results_NF %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#Visualise Results_NF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_NF%>% 
  conf_mat(GDDiag,.pred_class) %>% 
  autoplot()
```

```{r}
#Metrics
ev_met1_NF<-ev_met1(results_NF,truth = GDDiag, estimate = .pred_class)
Acc_NF<-yardstick::accuracy(results_NF, GDDiag,.pred_class)
Rec_NF<-yardstick::recall(results_NF, GDDiag, .pred_class)
#Plot Roc_Curve
curve_NF <- results_NF %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_NF

```

```{r}
#Evaluate AUC
auc_NF <- results_NF %>% 
  roc_auc(GDDiag, .pred_Yes)
NFMET<-list(auc_NF,ev_met1_NF, Rec_NF, Acc_NF)
kable(NFMET)
```

```{r}
NFMETCurVe<-list(NFMET, curve_NF)
NFMETCurVe
```

```{r}
#Lasso_Workflow
results_Lasso %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#Visualise Results_NF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_Lasso%>% 
  conf_mat(GDDiag,.pred_class) %>% 
  autoplot()

```


```{r}
#Metrics
ev_met1_Lasso<-ev_met1(results_Lasso,truth = GDDiag, estimate = .pred_class)
ACC_Lasso<-yardstick::accuracy(results_Lasso, GDDiag,.pred_class)
Rec_Lasso<-yardstick::recall(results_Lasso, GDDiag, .pred_class)
#Plot Roc_Curve
curve_Lasso <- results_Lasso %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_Lasso
```

```{r}
#Evaluate AUC
auc_Lasso <- results_Lasso %>% 
  roc_auc(GDDiag, .pred_Yes)
LassoMET<-list(auc_Lasso,ev_met1_Lasso, Rec_Lasso, ACC_Lasso)
kable(LassoMET)

```

```{r}
LassoMETCurVe<-list(LassoMET, curve_Lasso)
LassoMETCurVe

```


```{r}
#RF_Untuned_Workflow

results_RF%>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#Visualise Results_RF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_RF%>% 
  conf_mat(GDDiag,.pred_class) %>% 
  autoplot()

```

```{r}
#Metrics
ev_met1_RF<-ev_met1(results_RF,truth = GDDiag, estimate = .pred_class)
Rec_RF<-yardstick::recall(results_RF, GDDiag, .pred_class)
ACC_RF<-yardstick::accuracy(results_RF, GDDiag, .pred_class)
#Plot Roc_Curve
curve_RF <- results_RF %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_RF

```

```{r}
#Evaluate AUC
auc_RF <- results_RF %>% 
  roc_auc(GDDiag, .pred_Yes)
RFMET<-list(auc_RF,ev_met1_RF, Rec_RF, ACC_RF)
kable(RFMET)
RFMETCurVe<-list(RFMET, curve_RF)
RFMETCurVe

```

```{r}
#LogReg_Untuned_workflow

results_LR%>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#Visualise Results_RF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_LR%>% 
  conf_mat(GDDiag,.pred_class) %>% 
  autoplot()

```

```{r}
#Metrics
ev_met1_LR<-ev_met1(results_LR,truth = GDDiag, estimate = .pred_class)
Rec_LR<-yardstick::recall(results_LR, GDDiag, .pred_class)
ACC_LR<-yardstick::accuracy(results_LR, GDDiag, .pred_class)
#Plot Roc_Curve
curve_LR <- results_LR %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_LR

```

```{r}
#Evaluate AUC
auc_LR <- results_LR %>% 
  roc_auc(GDDiag, .pred_Yes)
LRMET<-list(auc_LR,ev_met1_LR, Rec_LR, ACC_LR)
kable(LRMET)

```

```{r}
LRMETCurVe<-list(LRMET, curve_LR)
LRMETCurVe

```

```{r}
#Kernel_SMV_Untuned
results_Kern%>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#Visualise Results_RF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_Kern%>% 
  conf_mat(GDDiag,.pred_class) %>% 
  autoplot()

```

```{r}
#Metrics
ev_met1_Kern<-ev_met1(results_Kern,truth = GDDiag, estimate = .pred_class)
Rec_Kern<-yardstick::recall(results_Kern, GDDiag, .pred_class)
ACC_Kern<-yardstick::accuracy(results_Kern, GDDiag, .pred_class)
#Plot Roc_Curve
curve_Kern <- results_Kern %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_Kern

```

```{r}
#Evaluate AUC
auc_Kern <- results_Kern %>% 
  roc_auc(GDDiag, .pred_Yes)
KernMET<-list(auc_Kern,ev_met1_Kern, Rec_Kern, ACC_Kern)
kable(KernMET)
KernMETCurVe<-list(KernMET, curve_LR)
KernMETCurVe

```

```{r}
#NB_Untuned
results_NB%>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#Visualise Results_RF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_NB%>% 
  conf_mat(GDDiag,.pred_class) %>% 
  autoplot()

```

```{r}
#Metrics
ev_met1_NB<-ev_met1(results_NB,truth = GDDiag, estimate = .pred_class)
Rec_NB<-yardstick::recall(results_NB, GDDiag, .pred_class)
ACC_NB<-yardstick::accuracy(results_NB, GDDiag, .pred_class)
#Plot Roc_Curve
curve_NB <- results_NB %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_NB

```

```{r}
#Evaluate AUC
auc_NB <- results_NB %>% 
  roc_auc(GDDiag, .pred_Yes)
NBMET<-list(auc_NB,ev_met1_NB, Rec_NB, ACC_NB)
kable(NBMET)


```

```{r}
NBMETCurVe<-list(NBMET, curve_NB)
NBMETCurVe

```
Fitting the different workflows on the testing data and extracting the most importnat recipe predictors for the different workflows for models available
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
Null_fit_Test<-Null_workflow%>%fit(test_data_GD_b)
Null_fit_Test  
Lasso_fit_Test<-lasso_workflow%>%fit(test_data_GD_b)
Lasso_fit_Test
RF_fit_Test<-RF_workflow%>%fit(test_data_GD_b)
RF_fit_Test
LogReg_fit_Test<-LOGGLM_workflow%>%fit(test_data_GD_b)
LogReg_fit_Test
Kernel_fit_Test<-Kernel_workflow%>%fit(test_data_GD_b)
Kernel_fit_Test
NB_fit_Test<-NB_workflow%>%fit(test_data_GD_b)
NB_fit_Test

Lasso_fit_Test %>% 
  extract_fit_parsnip() %>% 
 #Make VIP plot
 vip()

RF_fit_Test %>% 
  extract_fit_parsnip() %>% 
 #Make VIP plot
 vip()

LogReg_fit_Test %>% 
  extract_fit_parsnip() %>% 
 #Make VIP plot
 vip()


```
Tune Tunable Predictors RF, Kernel, Lasso, Logistic Regression

#Tune Kernel Algorithm
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
set.seed(123)
#Kernel
#first creating a tuning model
svm_spec_T <- svm_rbf(mode = "classification", engine = "kernlab", cost = tune(), rbf_sigma = tune())
#second creating a tuning workflow
Kernel_workflow_T<-workflow() %>% 
  add_recipe(GD_rec) %>% 
  add_model(svm_spec_T)
#third calling the workflow
Kernel_workflow_T
```

```{r}
# fourth creating the regular grid of 6 values for each tuning parameters
svm_grid <- grid_regular(parameters(svm_spec_T), levels = 10)
#fifth calling the grid
svm_grid
```

```{r}
#sixth tuning the grid
svm_res <- tune_grid(
  object = Kernel_workflow_T,resamples = train_boot,
  grid = svm_grid
)
  
```


```{r}

#Seventh collect tuning metrics
svm_res %>% 
  collect_metrics() %>% 
  slice_head(n = 20)
  #show_best()
```

```{r} 
  
  #Eighth Visualizing Tuning Metrics
  
svm_res %>% 
  collect_metrics() %>% 
  mutate(rbf_sigma = factor(rbf_sigma)) %>% 
  ggplot(mapping = aes(x = cost, y = mean, color = rbf_sigma)) +
  geom_line(size = 1.5, alpha = 0.7) +
  geom_point(size = 2) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "viridis", begin = .1)
```

```{r} 
#Nineth show the best model
svm_res %>% 
  show_best("accuracy")
```

```{r} 
svm_res%>%
  show_best("roc_auc")
```

```{r} 
# Tenth Select best model hyperparameters
best_svm <- svm_res %>% 
  select_best("accuracy", "roc_auc")
#11th Finalize the workoflow with the best SVM
final_wflow <- Kernel_workflow_T %>% 
  finalize_workflow(best_svm)
#12th Check the fit of the final Wflow on the training data
Tuned_Kernel_fit<-final_wflow%>%fit(train_data_GD_b)
Tuned_Kernel_fit
```

```{r} 
#Test the tuned Kernel on the test data
results_tuned_Kern<-test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols (Tuned_Kernel_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols(Tuned_Kernel_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_tuned_Kern)
``` 

```{r} 
#Tuned Kernel_Results
results_tuned_Kern %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#visualise CF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_tuned_Kern %>% 
  conf_mat(GDDiag, .pred_class) %>% 
  autoplot()
```

```{r} 

#Plot Roc_Curve
curve_kern_tuned <- results_tuned_Kern%>% 
  roc_curve(GDDiag, .pred_Yes)%>% 
  autoplot

curve_kern_tuned

```

```{r} 
# Evaluate ROC_AUC
auc_kern_tuned <- results_tuned_Kern %>% 
  roc_auc(GDDiag, .pred_Yes)
auc_kern_tuned
```

```{r} 
#AUC, PPV, ACC, Recall, Fmeas
ev_met1_TunKern<-ev_met1(results_tuned_Kern,truth = GDDiag, estimate = .pred_class)
Rec_TK<-yardstick::recall(results_tuned_Kern, GDDiag, .pred_class)
ACC_TK<-yardstick::accuracy(results_tuned_Kern, GDDiag, .pred_class)
TunKernMET<-list(auc_kern_tuned,ev_met1_TunKern, Rec_TK, ACC_TK)
kable(TunKernMET)
```
Tune Random Forests
```{r}
set.seed(123)
#RF
#first creating a tuning model
ranger_spec_T <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
)%>%
  set_mode("classification")%>%
  set_engine("ranger")
#second creating a tuning workflow
RF_workflow_T<-workflow() %>% 
  add_recipe(GD_rec) %>% 
  add_model(ranger_spec_T)
#third calling the workflow
RF_workflow_T
```

```{r}
# fourth tuning/testing the workflow to the resamples
set.seed(345)
RF_res <- tune_grid(
  RF_workflow_T,
  resamples = folds,
  grid = 20
)

```

```{r}
#Fifth collect and visualize tuning metrics
RF_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  )%>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```

```{r}
#Fifth for collecting tuning metrics
RF_res %>% 
  collect_metrics() %>% 
  slice_head(n = 10)

```

```{r}
#Nineth show the best model
RF_res %>% 
  show_best("accuracy", "roc_auc")
```

```{r}
# Tenth Select best model hyperparameters
best_RF <- RF_res %>% 
  select_best("accuracy", "roc_auc")
best_RF
```

```{r}
#11th Finalize the workoflow with the best SVM
final_wflow_RF <- RF_workflow_T %>% 
  finalize_workflow(best_RF)
#12th Check the fit of the final Wflow on the training data
Tuned_RF_fit<-final_wflow_RF%>%fit(train_data_GD_b)
Tuned_RF_fit

```







```{r}
#Test the tuned RF on the test data
results_tuned_RF<-test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols (Tuned_RF_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols(Tuned_RF_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_tuned_RF)
```


`

```{r}
#Tuned RF_Results
results_tuned_RF %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#visualise CF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_tuned_RF %>% 
  conf_mat(GDDiag, .pred_class) %>% 
  autoplot()
```

```{r}
#Plot Roc_Curve
curve_RF_tuned <- results_tuned_RF %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_RF_tuned
```

```{r}
# Evaluate ROC_AOC
auc_RF_tuned <- results_tuned_RF %>% 
  roc_auc(GDDiag, .pred_Yes)
ev_met1_TunRF<-ev_met1(results_tuned_RF,truth = GDDiag, estimate = .pred_class)
Rec_TRF<-yardstick::recall(results_tuned_RF, GDDiag, .pred_class)
ACC_TRF<-yardstick::accuracy(results_tuned_RF, GDDiag, .pred_class)
TunRFMET<-list(auc_RF_tuned,ev_met1_TunRF, Rec_TRF, ACC_TRF)
kable(TunRFMET)
```

#Tune Lasso
```{r}
set.seed(123)
#LASSO

#first creating a tuning model
tune_Lasso <- multinom_reg(penalty =tune(), mixture = 1)%>%
  set_mode("classification")%>%
  set_engine("glmnet")

#second creating a tuning workflow
Lasso_workflow_T<-workflow()%>% 
  add_recipe(GD_rec) %>% 
  add_model(tune_Lasso)
#third calling the workflow
Lasso_workflow_T
```
Define the Lamda grid
```{r}
set.seed(123)
lamda_grid <- grid_regular(penalty(), levels = 50)
lamda_grid
```

Tune the grid using our workflow object
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
doParallel::registerDoParallel()

set.seed(123)
lasso_grid <- tune_grid(
  Lasso_workflow_T,
  resamples = train_boot,
  grid = lamda_grid)

lasso_grid %>%
  collect_metrics()

```
Visualizing
```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
lasso_grid %>%
  collect_metrics() %>%
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
Best_Lasso <- lasso_grid%>%
  select_best("accuracy", "roc_auc")
Best_Lasso

```



```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Finalize the workoflow with the best LASSO
final_wflow_Lasso <-Lasso_workflow_T%>%
  finalize_workflow(Best_Lasso)
#Check the fit of the final Wflow on the training data
Tuned_Lasso_fit<-final_wflow_Lasso%>%fit(train_data_GD_b)
Tuned_Lasso_fit

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Test the tuned Lasso on the test data
results_tuned_Lasso<-test_data_GD_b%>% select(GDDiag) %>% 
  bind_cols(Tuned_Lasso_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols(Tuned_Lasso_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_tuned_Lasso)
```

```{r}
#Tuned Lasso_Results
results_tuned_Lasso %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#visualise CF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_tuned_Lasso %>% 
  conf_mat(GDDiag, .pred_class) %>% 
  autoplot()
     
```

```{r}
#Plot Roc_Curve
curve_Lasso_tuned <- results_tuned_Lasso %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_Lasso_tuned
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
# Evaluate ROC_AOC
auc_Lasso_tuned <- results_tuned_Lasso %>% 
  roc_auc(GDDiag, .pred_Yes)
auc_Lasso_tuned
```

```{r}
ev_met1_TunLasso<-ev_met1(results_tuned_Lasso,truth = GDDiag, estimate = .pred_class)
Rec_TLasso<-yardstick::recall(results_tuned_Lasso, GDDiag, .pred_class)
ACC_TLasso<-yardstick::accuracy(results_tuned_Lasso, GDDiag, .pred_class)
TunLassoMET<-list(auc_Lasso_tuned,ev_met1_TunLasso, Rec_TLasso, ACC_TLasso)
kable(TunLassoMET)
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

set.seed(123)
#Naive Bayes

#first creating a tuning model
tune_NB <- naive_Bayes(smoothness = tune(), Laplace = tune ())%>% 
  set_mode("classification")%>%
  set_engine("naivebayes")


#second creating a tuning workflow
NB_workflow_T<-workflow()%>% 
  add_recipe(GD_rec) %>% 
  add_model(tune_NB)
#third calling the workflow
NB_workflow_T


```


```{r}
# fourth tuning/testing the workflow to the resamples
set.seed(345)
NB_grid <- grid_regular(parameters(tune_NB), levels = 20)

NB_res<- tune_grid(
  NB_workflow_T,
  resamples = folds,
  grid = NB_grid)
  
```



```{r}
#Collect metrics
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

set.seed(123)
NB_res%>% 
  collect_metrics() %>% 
  slice_head(n = 10)
  
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
best_NB <- NB_res %>% 
  select_best("accuracy", "roc_auc")
best_NB
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#11th Finalize the workoflow with the best model
final_wflow_NB <- NB_workflow_T %>% 
  finalize_workflow(best_NB)
#12th Check the fit of the final Wflow on the training data
Tuned_NB_fit<-final_wflow_NB%>%fit(train_data_GD_b)
Tuned_NB_fit
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Test the tuned NB on the test data
results_tuned_NB<-test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols (Tuned_NB_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols(Tuned_NB_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_tuned_NB)
```


```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Tuned NB_Results
results_tuned_NB %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#visualise CF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_tuned_NB %>% 
  conf_mat(GDDiag, .pred_class) %>% 
  autoplot()
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Plot Roc_Curve
curve_NB_tuned <- results_tuned_NB %>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_NB_tuned
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
# Evaluate ROC_AUC
auc_NB_tuned <- results_tuned_NB %>% 
  roc_auc(GDDiag, .pred_Yes)
auc_NB_tuned
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
ev_met1_TunNB<-ev_met1(results_tuned_NB,truth = GDDiag, estimate = .pred_class)
Rec_TNB<-yardstick::recall(results_tuned_NB, GDDiag, .pred_class)
ACC_TNB<-yardstick::accuracy(results_tuned_NB, GDDiag, .pred_class)
TunNBMET<-list(auc_NB_tuned,ev_met1_TunNB, Rec_TNB, ACC_TNB)
kable(TunNBMET)
```

```{r}

echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

set.seed(123)
#Logistic Regression

#first creating a tuning model
tune_LR <- logistic_reg(penalty = tune(), mixture = tune())%>% 
  set_mode("classification")%>%
  set_engine("glmnet")


#second creating a tuning workflow
LR_workflow_T<-workflow()%>% 
  add_recipe(GD_rec) %>% 
  add_model(tune_LR)
#third calling the workflow
LR_workflow_T

```


```{r}

set.seed(345)
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

LR_grid <- grid_regular(parameters(tune_LR), levels = 20)

LR_res<- tune_grid(
  LR_workflow_T,
  resamples = folds,
  grid = LR_grid)

LR_res

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

set.seed(123)
LR_res%>% 
  collect_metrics() %>% 
  slice_head(n = 10)

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
best_LR <- LR_res %>% 
  select_best("accuracy", "roc_auc")
best_LR
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#11th Finalize the workoflow with the best model
final_wflow_LR <- LR_workflow_T %>% 
  finalize_workflow(best_LR)
#12th Check the fit of the final Wflow on the training data
Tuned_LR_fit<-final_wflow_LR%>%fit(train_data_GD_b)
Tuned_LR_fit
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Test the tuned NB on the test data
results_tuned_LR<-test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols (Tuned_LR_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols(Tuned_LR_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_tuned_LR)
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Tuned NB_Results
results_tuned_LR %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#visualise CF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_tuned_LR %>% 
  conf_mat(GDDiag, .pred_class) %>% 
  autoplot()

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Plot Roc_Curve
curve_LR_tuned <- results_tuned_LR%>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_LR_tuned
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
# Evaluate ROC_AUC
auc_LR_tuned <- results_tuned_LR %>% 
  roc_auc(GDDiag, .pred_Yes)
auc_LR_tuned

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
ev_met1_TunLR<-ev_met1(results_tuned_LR,truth = GDDiag, estimate = .pred_class)
Rec_TLR<-yardstick::recall(results_tuned_LR, GDDiag, .pred_class)
ACC_TLR<-yardstick::accuracy(results_tuned_LR, GDDiag, .pred_class)
TunLRMET<-list(auc_LR_tuned,ev_met1_TunLR, Rec_TLR, ACC_TLR)
kable(TunLRMET)

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

set.seed(123)
#xgb_tree

#first creating a tuning model
tune_xgb_t <- boost_tree(
  trees = 1000,
  tree_depth = tune(), min_n = tune(),
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(), mtry = tune(),         ## randomness
  learn_rate = tune()                          ## step size
) %>%
  set_engine("xgboost") %>%
  set_mode("classification")


#second creating a tuning workflow
xgb_workflow_T<-workflow()%>% 
  add_recipe(GD_rec) %>% 
  add_model(tune_xgb_t)
#third calling the workflow
xgb_workflow_T

```

```{r}

set.seed(345)
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), train_data_GD_b),
  learn_rate(),
  size = 30
)

xgb_res<- tune_grid(
  xgb_workflow_T,
  resamples = folds,
  grid = xgb_grid)

xgb_res
```

```{r}

set.seed(345)
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

set.seed(123)
xgb_res%>% 
  collect_metrics() %>% 
  slice_head(n = 10)

```

```{r}

set.seed(345)
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

best_xgb <- xgb_res%>% 
  select_best("accuracy", "roc_auc")
best_xgb
```

```{r}

echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#11th Finalize the workoflow with the best model
final_wflow_xgb <- xgb_workflow_T %>% 
  finalize_workflow(best_xgb)
#12th Check the fit of the final Wflow on the training data
Tuned_xgb_fit<-final_wflow_xgb%>%fit(train_data_GD_b)
Tuned_xgb_fit
```

```{r}

echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Test the tuned NB on the test data
results_tuned_xgb<-test_data_GD_b %>% select(GDDiag) %>% 
  bind_cols (Tuned_xgb_fit%>% 
              predict(new_data = test_data_GD_b)) %>% 
  bind_cols(Tuned_xgb_fit%>% 
              predict(new_data = test_data_GD_b, type = "prob"))
kable(results_tuned_xgb)

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)

#Tuned xgb_Results
results_tuned_xgb %>% 
  conf_mat(truth = GDDiag, estimate = .pred_class)
#visualise CF
update_geom_defaults(geom = "rect", new = list(fill = "midnightblue", alpha = 0.7))
results_tuned_xgb %>% 
  conf_mat(GDDiag, .pred_class) %>% 
  autoplot()

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
#Plot Roc_Curve
curve_xgb_tuned <- results_tuned_xgb%>% 
  roc_curve(GDDiag, .pred_Yes) %>% 
  autoplot
curve_xgb_tuned
```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
# Evaluate ROC_AUC
auc_xgb_tuned <- results_tuned_xgb %>% 
  roc_auc(GDDiag, .pred_Yes)
auc_xgb_tuned

```

```{r}
echo=FALSE
error=FALSE
warning=FALSE
options(scipen = 999, digits=3, max.print=999999, show.signif.stars=TRUE)
ev_met1_Tunxgb<-ev_met1(results_tuned_xgb,truth = GDDiag, estimate = .pred_class)
Rec_Txgb<-yardstick::recall(results_tuned_xgb, GDDiag, .pred_class)
ACC_Txgb<-yardstick::accuracy(results_tuned_xgb, GDDiag, .pred_class)
TunxgbMET<-list(auc_xgb_tuned,ev_met1_Tunxgb, Rec_Txgb, ACC_Txgb)
kable(TunxgbMET)

```

```

